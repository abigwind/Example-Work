{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98ad8870-b885-482d-889d-1e1998830bfd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Use test set to measure the accuracy of our model on new data\n",
    "lrCvPredictions = lrCvModel.transform(testData)\n",
    "\n",
    "display(lrCvPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a859ee5-42bf-44a4-a167-09580f855492",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gbCvPredictions = gbCvModel.transform(testData)\n",
    "\n",
    "display(gbCvPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7fceda1e-5064-4bf4-bf78-a699c94f2b39",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print_performance_metrics(lrCvPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0124fad3-7175-4e46-887c-05f4d930e9f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print_performance_metrics(gbCvPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8072e7bb-ea2b-4569-8b3e-6a565a46868a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print('Model Intercept: ', lrCvModel.bestModel.intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df770dd0-5edd-400a-8bea-6b9a09952f2b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lrWeights = lrCvModel.bestModel.coefficients\n",
    "lrWeights = [(float(w),) for w in lrWeights]  # convert numpy type to float, and to tuple\n",
    "lrWeightsDF = sqlContext.createDataFrame(lrWeights, [\"Feature Weight\"])\n",
    "display(lrWeightsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a06dce02-7fd8-4545-a96f-53cbf84ef408",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Question 8.1 Answer ###\n",
    "\n",
    "# from: https://stackoverflow.com/questions/42935914/how-to-map-features-from-the-output-of-a-vectorassembler-back-to-the-column-name\n",
    "#lrFeatureImportance = pd.DataFrame([(name, lrModel.bestModel.featureImportances[idx]) for idx, name in attrs],columns=['feature_name','feature_importance'])\n",
    "\n",
    "#print(lrFeatureImportance.sort_values(by=['feature_importance'],ascending =False))\n",
    "coefficients = lrCvModel.bestModel.coefficients.toArray()\n",
    "\n",
    "features_col_name = lrCvModel.bestModel.getOrDefault(\"featuresCol\")\n",
    "\n",
    "feature_names = trainingData.columns\n",
    "feature_names.remove('label')\n",
    "\n",
    "features = [feature_name for feature_name in feature_names]\n",
    "\n",
    "feature_coefficient_table = list(zip(features, coefficients))\n",
    "\n",
    "for feature_name, coefficient in feature_coefficient_table:\n",
    "    print(f\"Feature: {feature_name}, Coefficient: {coefficient}\")\n",
    "\n",
    "\n",
    "feature_names = trainingData.columns\n",
    "feature_names.remove(\"label\")  # If you need to remove the label column\n",
    "\n",
    "# Retrieve feature importances from the GBT model\n",
    "feature_importances = gbCvModel.bestModel.featureImportances.toArray()\n",
    "\n",
    "# Create a DataFrame with feature names and their importances\n",
    "gbt_feature_importance = pd.DataFrame(list(zip(feature_names, feature_importances)), columns=['feature_name', 'feature_importance'])\n",
    "\n",
    "# Sort the DataFrame by feature importance in descending order\n",
    "gbt_feature_importance = gbt_feature_importance.sort_values(by='feature_importance', ascending=False)\n",
    "\n",
    "# Print the sorted DataFrame\n",
    "print(gbt_feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea9ebbb1-c3cc-490e-90ff-13c2004b26aa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Question 9.1 Answer ###\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=100)\n",
    "\n",
    "rfModel = rf.fit(trainingData)\n",
    "\n",
    "rfFeatureImportance = rfModel.featureImportances.toArray()\n",
    "\n",
    "feature_names = trainingData.columns\n",
    "feature_names.remove(\"label\")\n",
    "\n",
    "rf_feature_importance = pd.DataFrame(list(zip(feature_names, feature_importances)), columns=['feature_name', 'feature_importance'])\n",
    "\n",
    "rf_feature_importance = rf_feature_importance.sort_values(by='feature_importance', ascending=False)\n",
    "\n",
    "print(rf_feature_importance)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Matt Nelson (Part 2)",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
